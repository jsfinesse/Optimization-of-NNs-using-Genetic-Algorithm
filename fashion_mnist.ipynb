{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwAwzXpaXNze"
      },
      "source": [
        "### Import libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nr-Yx4BZXNzi"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUOKdz0tXNzk"
      },
      "source": [
        "### Preprocess data, normalize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n5iywLRXNzk",
        "outputId": "8309ae07-ad63-4a19-e307-6b654cccb955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of X_train:  (60000, 28, 28)\n",
            "shape of X_test:  (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(\"shape of X_train: \", X_train.shape)\n",
        "print(\"shape of X_test: \", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M9IA5cfXNzm"
      },
      "source": [
        "### Create ANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCnQAg-1XNzm",
        "outputId": "574dad45-7b64-41e6-eccd-dac69fad6e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "def init():\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation= 'relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "modelInfo = init()\n",
        "modelInfo.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VymG52KN-cQ7",
        "outputId": "4975c65b-1dcc-4af2-c441-bcf0e422e2dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4976 - accuracy: 0.8243 - val_loss: 0.4144 - val_accuracy: 0.8561\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3754 - accuracy: 0.8643 - val_loss: 0.4121 - val_accuracy: 0.8525\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3373 - accuracy: 0.8765 - val_loss: 0.3673 - val_accuracy: 0.8668\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3144 - accuracy: 0.8853 - val_loss: 0.3591 - val_accuracy: 0.8720\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2971 - accuracy: 0.8907 - val_loss: 0.3490 - val_accuracy: 0.8770\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2800 - accuracy: 0.8982 - val_loss: 0.3507 - val_accuracy: 0.8721\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2679 - accuracy: 0.9006 - val_loss: 0.3467 - val_accuracy: 0.8763\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2568 - accuracy: 0.9053 - val_loss: 0.3369 - val_accuracy: 0.8831\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2500 - accuracy: 0.9067 - val_loss: 0.3397 - val_accuracy: 0.8783\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2396 - accuracy: 0.9098 - val_loss: 0.3408 - val_accuracy: 0.8794\n"
          ]
        }
      ],
      "source": [
        "model = init()\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVkNTqvr-7Xl",
        "outputId": "42087fde-a54b-4a3b-e421-5ac14d7e4f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 809us/step - loss: 0.3408 - accuracy: 0.8794\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3407944440841675, 0.8794000148773193]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEsjhXTHXNzn"
      },
      "source": [
        "### Train model for 1 epoch and return trained models with current loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wJ_WDzqdXNzo"
      },
      "outputs": [],
      "source": [
        "def train(models):\n",
        "  \n",
        "    losses = []\n",
        "     \n",
        "    for i in range(len(models)):\n",
        "        history = models[i].fit(x=X_train,y=y_train, epochs=1, validation_data=(X_test, y_test))\n",
        "        losses.append(round(history.history['loss'][-1], 4))\n",
        "        \n",
        "    return models, losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8rskUFDzXNzo"
      },
      "outputs": [],
      "source": [
        "no_of_generations = 10\n",
        "no_of_individuals = 10\n",
        "mutate_factor = 0.1\n",
        "individuals = []\n",
        "\n",
        "layers = [1, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DWF1MDp0rP5"
      },
      "source": [
        "### Define mutate function to perform mutation of weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RBdoWG_zXNzp"
      },
      "outputs": [],
      "source": [
        "def mutate(new_individual):\n",
        "    for layer in layers:\n",
        "        for bias in range(len(new_individual.layers[layer].get_weights()[1])):\n",
        "            n = random.random()\n",
        "            if n < mutate_factor:\n",
        "                new_individual.layers[layer].get_weights(\n",
        "                )[1][bias] *= random.uniform(-0.5, 0.5)\n",
        "\n",
        "    for layer in layers:\n",
        "        for weight in new_individual.layers[layer].get_weights()[0]:\n",
        "            n = random.random()\n",
        "            if n < mutate_factor:\n",
        "                for j in range(len(weight)):\n",
        "                    if random.random() < mutate_factor:\n",
        "                        new_individual.layers[layer].get_weights(\n",
        "                        )[0][j] *= random.uniform(-0.5, 0.5)\n",
        "\n",
        "    return new_individual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unPdHHDW0zTh"
      },
      "source": [
        "### Define crossover function to form new generation with better weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "akm-n1ahXNzp"
      },
      "outputs": [],
      "source": [
        "def crossover(individuals_param):\n",
        "    new_individuals = [individuals_param[0], individuals_param[1]]\n",
        "\n",
        "    for j in range(2, no_of_individuals):\n",
        "        if j < (no_of_individuals - 2):\n",
        "            if j == 2:\n",
        "                parentA = random.choice(individuals_param[:3])\n",
        "                parentB = random.choice(individuals_param[:3])\n",
        "            else:\n",
        "                parentA = random.choice(individuals_param[:])\n",
        "                parentB = random.choice(individuals_param[:])\n",
        "\n",
        "            for j in layers:\n",
        "                temp = parentA.layers[j].get_weights()[1]\n",
        "                parentA.layers[j].get_weights()[1] = parentB.layers[j].get_weights()[1]\n",
        "                parentB.layers[j].get_weights()[1] = temp\n",
        "\n",
        "            new_individual = random.choice([parentA, parentB])\n",
        "\n",
        "        else:\n",
        "            new_individual = random.choice(individuals_param[:])\n",
        "\n",
        "        new_individuals.append(mutate(new_individual))\n",
        "        # new_individuals.append(new_individual)\n",
        "\n",
        "    return new_individuals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGPHtKAs4pDv"
      },
      "source": [
        "### Define evolve function to sort current population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BsvGSUG0XNzq"
      },
      "outputs": [],
      "source": [
        "def evolve(individuals_param, losses_param):\n",
        "    sorted_y_idx_list = sorted(range(len(losses_param)), key=lambda x: losses_param[x])\n",
        "    individuals_param = [individuals_param[x] for x in sorted_y_idx_list]\n",
        "\n",
        "    # winners = individuals[:6]\n",
        "\n",
        "    new_individuals = crossover(individuals_param)\n",
        "\n",
        "    return new_individuals\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZPKQ6Ve4sxs"
      },
      "source": [
        "### Train individuals and evolve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo94kJY3XNzq",
        "outputId": "f745ca53-57d7-4eb6-e1e6-47ebfe2f3e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4993 - accuracy: 0.8242 - val_loss: 0.4120 - val_accuracy: 0.8553\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4982 - accuracy: 0.8245 - val_loss: 0.4145 - val_accuracy: 0.8538\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4934 - accuracy: 0.8273 - val_loss: 0.4194 - val_accuracy: 0.8538\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4952 - accuracy: 0.8257 - val_loss: 0.4358 - val_accuracy: 0.8386\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5006 - accuracy: 0.8242 - val_loss: 0.4234 - val_accuracy: 0.8516\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5014 - accuracy: 0.8253 - val_loss: 0.4255 - val_accuracy: 0.8474\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5030 - accuracy: 0.8229 - val_loss: 0.4403 - val_accuracy: 0.8451\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5020 - accuracy: 0.8246 - val_loss: 0.4503 - val_accuracy: 0.8411\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5006 - accuracy: 0.8233 - val_loss: 0.4328 - val_accuracy: 0.8450\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5038 - accuracy: 0.8225 - val_loss: 0.4726 - val_accuracy: 0.8326\n",
            "[0.4993, 0.4982, 0.4934, 0.4952, 0.5006, 0.5014, 0.503, 0.502, 0.5006, 0.5038]\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3710 - accuracy: 0.8650 - val_loss: 0.3781 - val_accuracy: 0.8632\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3737 - accuracy: 0.8643 - val_loss: 0.3865 - val_accuracy: 0.8596\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3743 - accuracy: 0.8654 - val_loss: 0.4244 - val_accuracy: 0.8481\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8771 - val_loss: 0.3876 - val_accuracy: 0.8545\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3725 - accuracy: 0.8673 - val_loss: 0.3861 - val_accuracy: 0.8589\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3371 - accuracy: 0.8762 - val_loss: 0.3703 - val_accuracy: 0.8654\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3374 - accuracy: 0.8764 - val_loss: 0.3565 - val_accuracy: 0.8723\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3084 - accuracy: 0.8875 - val_loss: 0.3445 - val_accuracy: 0.8793\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3738 - accuracy: 0.8656 - val_loss: 0.3921 - val_accuracy: 0.8619\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3773 - accuracy: 0.8637 - val_loss: 0.3892 - val_accuracy: 0.8629\n",
            "[0.371, 0.3737, 0.3743, 0.3356, 0.3725, 0.3371, 0.3374, 0.3084, 0.3738, 0.3773]\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2926 - accuracy: 0.8915 - val_loss: 0.3848 - val_accuracy: 0.8630\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2761 - accuracy: 0.8974 - val_loss: 0.3376 - val_accuracy: 0.8769\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2665 - accuracy: 0.9003 - val_loss: 0.3460 - val_accuracy: 0.8760\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3345 - accuracy: 0.8773 - val_loss: 0.3630 - val_accuracy: 0.8700\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2552 - accuracy: 0.9057 - val_loss: 0.3571 - val_accuracy: 0.8718\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3372 - accuracy: 0.8762 - val_loss: 0.3621 - val_accuracy: 0.8690\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2445 - accuracy: 0.9086 - val_loss: 0.3544 - val_accuracy: 0.8776\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2389 - accuracy: 0.9115 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3115 - accuracy: 0.8861 - val_loss: 0.3578 - val_accuracy: 0.8732\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3117 - accuracy: 0.8860 - val_loss: 0.3499 - val_accuracy: 0.8708\n",
            "[0.2926, 0.2761, 0.2665, 0.3345, 0.2552, 0.3372, 0.2445, 0.2389, 0.3115, 0.3117]\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2293 - accuracy: 0.9148 - val_loss: 0.3276 - val_accuracy: 0.8858\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2222 - accuracy: 0.9172 - val_loss: 0.3556 - val_accuracy: 0.8777\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2157 - accuracy: 0.9192 - val_loss: 0.3314 - val_accuracy: 0.8876\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2090 - accuracy: 0.9210 - val_loss: 0.3434 - val_accuracy: 0.8837\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2954 - accuracy: 0.8909 - val_loss: 0.3706 - val_accuracy: 0.8662\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2017 - accuracy: 0.9235 - val_loss: 0.3652 - val_accuracy: 0.8754\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1974 - accuracy: 0.9264 - val_loss: 0.3386 - val_accuracy: 0.8897\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2789 - accuracy: 0.8979 - val_loss: 0.3422 - val_accuracy: 0.8787\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1928 - accuracy: 0.9267 - val_loss: 0.3526 - val_accuracy: 0.8840\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1883 - accuracy: 0.9291 - val_loss: 0.3466 - val_accuracy: 0.8879\n",
            "[0.2293, 0.2222, 0.2157, 0.209, 0.2954, 0.2017, 0.1974, 0.2789, 0.1928, 0.1883]\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1834 - accuracy: 0.9315 - val_loss: 0.3586 - val_accuracy: 0.8853\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1783 - accuracy: 0.9322 - val_loss: 0.3606 - val_accuracy: 0.8863\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1723 - accuracy: 0.9352 - val_loss: 0.3519 - val_accuracy: 0.8892\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1700 - accuracy: 0.9358 - val_loss: 0.3625 - val_accuracy: 0.8858\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2658 - accuracy: 0.9010 - val_loss: 0.3476 - val_accuracy: 0.8744\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2552 - accuracy: 0.9048 - val_loss: 0.3371 - val_accuracy: 0.8778\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1653 - accuracy: 0.9369 - val_loss: 0.3742 - val_accuracy: 0.8842\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1610 - accuracy: 0.9401 - val_loss: 0.3675 - val_accuracy: 0.8847\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1558 - accuracy: 0.9408 - val_loss: 0.3820 - val_accuracy: 0.8874\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2454 - accuracy: 0.9068 - val_loss: 0.3275 - val_accuracy: 0.8889\n",
            "[0.1834, 0.1783, 0.1723, 0.17, 0.2658, 0.2552, 0.1653, 0.161, 0.1558, 0.2454]\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1553 - accuracy: 0.9416 - val_loss: 0.3891 - val_accuracy: 0.8794\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1501 - accuracy: 0.9434 - val_loss: 0.4109 - val_accuracy: 0.8802\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1466 - accuracy: 0.9446 - val_loss: 0.3933 - val_accuracy: 0.8840\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1437 - accuracy: 0.9462 - val_loss: 0.3974 - val_accuracy: 0.8873\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1433 - accuracy: 0.9459 - val_loss: 0.3924 - val_accuracy: 0.8877\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1380 - accuracy: 0.9479 - val_loss: 0.4033 - val_accuracy: 0.8901\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1362 - accuracy: 0.9483 - val_loss: 0.4004 - val_accuracy: 0.8880\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1333 - accuracy: 0.9492 - val_loss: 0.4214 - val_accuracy: 0.8846\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1279 - accuracy: 0.9525 - val_loss: 0.4391 - val_accuracy: 0.8871\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1291 - accuracy: 0.9516 - val_loss: 0.4296 - val_accuracy: 0.8876\n",
            "[0.1553, 0.1501, 0.1466, 0.1437, 0.1433, 0.138, 0.1362, 0.1333, 0.1279, 0.1291]\n",
            "1875/1875 [==============================] - 2s 985us/step - loss: 0.1242 - accuracy: 0.9539 - val_loss: 0.4354 - val_accuracy: 0.8873\n",
            "1875/1875 [==============================] - 2s 963us/step - loss: 0.1252 - accuracy: 0.9521 - val_loss: 0.4478 - val_accuracy: 0.8866\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1216 - accuracy: 0.9542 - val_loss: 0.4398 - val_accuracy: 0.8897\n",
            "1875/1875 [==============================] - 2s 972us/step - loss: 0.1177 - accuracy: 0.9559 - val_loss: 0.4463 - val_accuracy: 0.8918\n",
            "1875/1875 [==============================] - 2s 969us/step - loss: 0.1163 - accuracy: 0.9559 - val_loss: 0.4615 - val_accuracy: 0.8857\n",
            "1875/1875 [==============================] - 2s 978us/step - loss: 0.1160 - accuracy: 0.9566 - val_loss: 0.4720 - val_accuracy: 0.8857\n",
            "1875/1875 [==============================] - 2s 983us/step - loss: 0.1123 - accuracy: 0.9584 - val_loss: 0.4467 - val_accuracy: 0.8897\n",
            "1875/1875 [==============================] - 2s 982us/step - loss: 0.1098 - accuracy: 0.9585 - val_loss: 0.4769 - val_accuracy: 0.8858\n",
            "1875/1875 [==============================] - 2s 974us/step - loss: 0.1096 - accuracy: 0.9588 - val_loss: 0.4630 - val_accuracy: 0.8889\n",
            "1875/1875 [==============================] - 2s 974us/step - loss: 0.1062 - accuracy: 0.9598 - val_loss: 0.4650 - val_accuracy: 0.8888\n",
            "[0.1242, 0.1252, 0.1216, 0.1177, 0.1163, 0.116, 0.1123, 0.1098, 0.1096, 0.1062]\n",
            "1875/1875 [==============================] - 2s 986us/step - loss: 0.1045 - accuracy: 0.9610 - val_loss: 0.5258 - val_accuracy: 0.8791\n",
            "1875/1875 [==============================] - 2s 996us/step - loss: 0.1051 - accuracy: 0.9607 - val_loss: 0.4951 - val_accuracy: 0.8865\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1017 - accuracy: 0.9614 - val_loss: 0.4964 - val_accuracy: 0.8907\n",
            "1875/1875 [==============================] - 2s 982us/step - loss: 0.1005 - accuracy: 0.9631 - val_loss: 0.5090 - val_accuracy: 0.8893\n",
            "1875/1875 [==============================] - 2s 972us/step - loss: 0.0959 - accuracy: 0.9637 - val_loss: 0.5075 - val_accuracy: 0.8872\n",
            "1875/1875 [==============================] - 2s 996us/step - loss: 0.0970 - accuracy: 0.9631 - val_loss: 0.5666 - val_accuracy: 0.8772\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0959 - accuracy: 0.9645 - val_loss: 0.5392 - val_accuracy: 0.8817\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0936 - accuracy: 0.9656 - val_loss: 0.5015 - val_accuracy: 0.8925\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0918 - accuracy: 0.9660 - val_loss: 0.5183 - val_accuracy: 0.8856\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0941 - accuracy: 0.9647 - val_loss: 0.5432 - val_accuracy: 0.8850\n",
            "[0.1045, 0.1051, 0.1017, 0.1005, 0.0959, 0.097, 0.0959, 0.0936, 0.0918, 0.0941]\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0880 - accuracy: 0.9673 - val_loss: 0.5754 - val_accuracy: 0.8891\n",
            "1875/1875 [==============================] - 2s 977us/step - loss: 0.0898 - accuracy: 0.9660 - val_loss: 0.5363 - val_accuracy: 0.8901\n",
            "1875/1875 [==============================] - 2s 976us/step - loss: 0.0852 - accuracy: 0.9681 - val_loss: 0.5506 - val_accuracy: 0.8866\n",
            "1875/1875 [==============================] - 2s 982us/step - loss: 0.0861 - accuracy: 0.9673 - val_loss: 0.5682 - val_accuracy: 0.8834\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0844 - accuracy: 0.9682 - val_loss: 0.5377 - val_accuracy: 0.8907\n",
            "1875/1875 [==============================] - 2s 995us/step - loss: 0.0826 - accuracy: 0.9696 - val_loss: 0.5921 - val_accuracy: 0.8865\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0834 - accuracy: 0.9687 - val_loss: 0.5622 - val_accuracy: 0.8882\n",
            "1875/1875 [==============================] - 2s 978us/step - loss: 0.0803 - accuracy: 0.9706 - val_loss: 0.5663 - val_accuracy: 0.8898\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0794 - accuracy: 0.9704 - val_loss: 0.5715 - val_accuracy: 0.8902\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0789 - accuracy: 0.9704 - val_loss: 0.6177 - val_accuracy: 0.8868\n",
            "[0.088, 0.0898, 0.0852, 0.0861, 0.0844, 0.0826, 0.0834, 0.0803, 0.0794, 0.0789]\n",
            "1875/1875 [==============================] - 2s 986us/step - loss: 0.0773 - accuracy: 0.9708 - val_loss: 0.5972 - val_accuracy: 0.8894\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0762 - accuracy: 0.9716 - val_loss: 0.6221 - val_accuracy: 0.8926\n",
            "1875/1875 [==============================] - 2s 983us/step - loss: 0.0761 - accuracy: 0.9714 - val_loss: 0.6154 - val_accuracy: 0.8864\n",
            "1875/1875 [==============================] - 2s 993us/step - loss: 0.0719 - accuracy: 0.9727 - val_loss: 0.6322 - val_accuracy: 0.8863\n",
            "1875/1875 [==============================] - 2s 987us/step - loss: 0.0740 - accuracy: 0.9722 - val_loss: 0.6370 - val_accuracy: 0.8861\n",
            "1875/1875 [==============================] - 2s 986us/step - loss: 0.0722 - accuracy: 0.9729 - val_loss: 0.6119 - val_accuracy: 0.8872\n",
            "1875/1875 [==============================] - 2s 987us/step - loss: 0.0753 - accuracy: 0.9713 - val_loss: 0.6501 - val_accuracy: 0.8900\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0672 - accuracy: 0.9742 - val_loss: 0.6303 - val_accuracy: 0.8904\n",
            "1875/1875 [==============================] - 2s 989us/step - loss: 0.0722 - accuracy: 0.9726 - val_loss: 0.6486 - val_accuracy: 0.8877\n",
            "1875/1875 [==============================] - 2s 994us/step - loss: 0.0677 - accuracy: 0.9747 - val_loss: 0.6711 - val_accuracy: 0.8875\n",
            "[0.0773, 0.0762, 0.0761, 0.0719, 0.074, 0.0722, 0.0753, 0.0672, 0.0722, 0.0677]\n"
          ]
        }
      ],
      "source": [
        "for i in range(no_of_individuals):\n",
        "        individuals.append(init())\n",
        "\n",
        "for generation in range(no_of_generations):\n",
        "    individuals, losses = train(individuals)\n",
        "    print(losses)\n",
        "\n",
        "    individuals = evolve(individuals, losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijQz1LGXNzr",
        "outputId": "c9981f14-9227-4b04-b033-2bbac1d0864d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 697us/step - loss: 0.6711 - accuracy: 0.8875\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6711329221725464, 0.887499988079071]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = individuals[0]\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "EBf09w09d7gh",
        "outputId": "01f28153-ea73-4649-b857-5d592ed323f6"
      },
      "outputs": [],
      "source": [
        "# p_test = model.predict(X_test).argmax(axis=1)\n",
        "# print(X_test.shape)\n",
        "# i = numpy.random.choice(X_test.shape[0], replace=False)\n",
        "# plt.imshow(X_test[i], cmap= 'gray')\n",
        "# plt.title(\"True label: %s Predicted: %s\" % (y_test[i], p_test[i]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mnist.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8a0916fdec204e0a24c380f434be5b41b91f5eb4bf903fceed4db23957524ed9"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('genetic-algo')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
